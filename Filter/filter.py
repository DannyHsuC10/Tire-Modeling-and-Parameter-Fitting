# è³‡æ–™éæ¿¾å™¨
"""
è™•ç†ç¨‹åº:
1. æ¸…æ‰é ­å°¾è³‡æ–™
2. å»ºç«‹å¸ƒæ—é®ç½©
3. å¥—ç”¨é®ç½©ä¸¦åˆªæ‰ NaN
4. ä½é€šæ¿¾æ³¢ï¼ˆå¯é¸ï¼‰
5. è³‡æ–™è½‰æ›
"""
import pandas as pd
from pathlib import Path
import numpy as np
import json
from scipy.signal import butter, filtfilt, welch

# filter.py æ‰€åœ¨è³‡æ–™å¤¾
FILTER_DIR = Path(__file__).resolve().parent
# å°ˆæ¡ˆæ ¹ç›®éŒ„ project/
PROJECT_DIR = FILTER_DIR.parent

# ===========================================(è¼‰å…¥)
def load_tire_data(file_path):# è¼‰å…¥è³‡æ–™
    file_path = Path(file_path)

    if file_path.suffix.lower() == ".csv":
        df = pd.read_csv(file_path)
    elif file_path.suffix.lower() in [".xlsx", ".xls"]:
        df = pd.read_excel(file_path)
    else:
        raise ValueError("Unsupported file format")

    return df

# ===========================================(è³‡æ–™æ¸…æ´—)
def trim_dataframe_edges(df: pd.DataFrame, n_head: int = 0, n_tail: int = 0, fill_value=np.nan) -> pd.DataFrame:# é ­å°¾æ¸…æ´—
    """
    æ¸…æ‰ DataFrame é–‹é ­èˆ‡çµå°¾çš„è³‡æ–™

    df: pandas DataFrame
    n_head: è¦æ¸…æ‰çš„é–‹é ­åˆ—æ•¸
    n_tail: è¦æ¸…æ‰çš„çµå°¾åˆ—æ•¸
    fill_value: æ¸…æ‰å¾Œå¡«å…¥çš„å€¼ï¼Œé è¨­ NaN

    è¿”å›æ–°çš„ DataFrame
    """
    df_clean = df.copy()

    if n_head > 0:
        df_clean.iloc[:n_head, :] = fill_value

    if n_tail > 0:
        df_clean.iloc[-n_tail:, :] = fill_value

    return df_clean

# ===========================================(å¸ƒæ—é®ç½©)
class MaskBuilder:
    def __init__(self, json_path: str):
        """
        json_path: Filtering_Limits.json è·¯å¾‘
        """
        with open(json_path, "r") as f:
            self.limits = json.load(f)

    # =========================
    # åŸºæœ¬å·¥å…·
    # =========================
    @staticmethod
    def enforce_min_segment_length(mask: np.ndarray, min_len: int) -> np.ndarray:
        """å°‡ mask ä¸­é€£çºŒ True é•·åº¦ < min_len çš„å€æ®µæ¸…é™¤"""
        mask = mask.copy()
        count = 0
        start = 0

        for i, val in enumerate(mask):
            if val:
                if count == 0:
                    start = i
                count += 1
            if (not val or i == len(mask) - 1) and count > 0:
                if count < min_len:
                    mask[start:start + count] = False
                count = 0
        return mask

    def build_mask_from_range(
        self,
        data: np.ndarray,
        min_val: float,
        max_val: float,
        min_len: int
    ) -> np.ndarray:
        """ä¸€èˆ¬ min / max ç¯„åœé®ç½©"""
        mask = (data >= min_val) & (data <= max_val)
        return self.enforce_min_segment_length(mask, min_len)

    # =========================
    # slope ç‰¹æ®Šé®ç½©
    # =========================
    @staticmethod
    def build_slope_mask(
        data: np.ndarray,
        pos_range,
        neg_range,
        slope_min,
        slope_max,
        min_len: int = 5
    ) -> np.ndarray:
        """
        å»ºç«‹ data æ–œç‡é®ç½©ï¼ˆé˜² NaN / é˜²çŸ­æ®µ / é˜²é€€åŒ–ï¼‰
        - å…¨å¸¸æ•¸æ®µä¹Ÿæœƒè¢«ç›´æ¥é€šé
        """
        data = np.asarray(data, dtype=float)

        in_pos = (data >= pos_range["min"]) & (data <= pos_range["max"])
        in_neg = (data >= neg_range["min"]) & (data <= neg_range["max"])
        merged = in_pos | in_neg

        mask = np.zeros_like(data, dtype=bool)

        # å¦‚æœå…¨éƒ¨éƒ½ç¬¦åˆ mergedï¼Œç›´æ¥å…¨é€šé
        if np.all(merged):
            mask[:] = True
            return mask

        zero_idx = np.where(~merged)[0]

        breaks = np.where(np.diff(zero_idx) > 1)[0]
        starts = zero_idx[np.r_[0, breaks + 1]]
        ends   = zero_idx[np.r_[breaks, len(zero_idx) - 1]]

        for s, e in zip(starts, ends):
            seg = data[s:e + 1]

            # â¶ é•·åº¦æª¢æŸ¥
            if len(seg) < min_len:
                continue

            # â· NaN / Inf æª¢æŸ¥
            if not np.all(np.isfinite(seg)):
                continue

            # â¸ é€€åŒ–æª¢æŸ¥ï¼ˆå…¨å¸¸æ•¸ï¼‰
            if np.std(seg) < 1e-6:
                mask[s:e+1] = True  # å…¨å¸¸æ•¸ç›´æ¥é€šé
                continue

            # â¹ æ–œç‡è¨ˆç®—ï¼ˆé˜²çˆ†ï¼‰
            try:
                x = np.arange(len(seg))
                slope = np.polyfit(x, seg, 1)[0]
            except np.linalg.LinAlgError:
                continue

            if slope_min <= slope <= slope_max:
                mask[s:e + 1] = True

        return mask

    # =========================
    # å°å¤–ä¸»ä»‹é¢
    # =========================
    def build_masks(
        self,
        df: pd.DataFrame,
        mask_type: str = "FX"
    ) -> dict:
        """
        df: pandas DataFrame
        mask_type: "FX" or "FY"
        
        é‚è¼¯ï¼š
        - æ¯å€‹æ¬„ä½å…§å­é®ç½©ç”¨ OR åˆä½µ
        - ä¸åŒæ¬„ä½ä¹‹é–“ç”¨ AND åˆä½µ
        """
        limits = self.limits[mask_type]
        masks = {}
        total_mask = np.ones(len(df), dtype=bool)

        for col, col_limits in limits.items():
            if "slope_min" in col_limits:
                # SL ç‰¹æ®Šè™•ç†
                slope_data = df[col].to_numpy(dtype=float)      # è½‰æˆ floatï¼Œéæ•¸å­—æœƒè®Š NaN
                numeric_slope = np.nan_to_num(slope_data, nan=0.0) # NaN è¦–ç‚º 0

                if np.all(numeric_slope == 0):
                    sl_mask = np.ones(len(numeric_slope), dtype=bool)
                else:
                    sl_mask = self.build_slope_mask(
                        numeric_slope,
                        col_limits["pos_range"],
                        col_limits["neg_range"],
                        col_limits["slope_min"],
                        col_limits["slope_max"]
                    )

                masks[col] = sl_mask
                total_mask &= sl_mask
            else:
                data = df[col].to_numpy()
                # å°æ¬„ä½å…§æ‰€æœ‰å­é®ç½©åš OR
                col_mask = np.zeros(len(df), dtype=bool)
                for name, params in col_limits.items():
                    mask = self.build_mask_from_range(
                        data,
                        params["min"],
                        params["max"],
                        params["n"]
                    )
                    col_mask |= mask  # OR
                    masks[name] = mask  # ä¿ç•™åŸæœ¬å„å­é®ç½©

                total_mask &= col_mask  # AND ä¸åŒæ¬„ä½

        # å°‡ total_mask ä¹Ÿå›å‚³
        masks["total_mask"] = total_mask
        return masks

# ===========================================(æ¿¾æ³¢å™¨)
def auto_lowpass_filter(# å‚…ç«‹è‘‰ä½é€šç‡æ³¢
    df: pd.DataFrame,
    fs: float = 1000.0,
    energy_ratio: float = 0.9,
    order: int = 5,
    min_cutoff: float = 0.001
) -> pd.DataFrame:
    """
    è‡ªå‹•ä½é€šæ¿¾æ³¢ï¼ˆå®‰å…¨ç‰ˆï¼‰
    é€é Welch PSD ç´¯ç©èƒ½é‡æ±ºå®š cutoff frequencyï¼Œ
    ä¸¦åŠ å…¥å®Œæ•´ä¿è­·æ©Ÿåˆ¶ï¼Œé¿å… cutoff = 0 æˆ–æ•¸å€¼çˆ†ç‚¸ã€‚

    df: pandas DataFrame
    fs: å–æ¨£é »ç‡ (Hz)
    energy_ratio: ä¿ç•™çš„è¨Šè™Ÿèƒ½é‡æ¯”ä¾‹ (å»ºè­° < 1ï¼Œä¾‹å¦‚ 0.95~0.99)
    order: Butterworth æ¿¾æ³¢å™¨éšæ•¸
    min_cutoff: æœ€å° cutoff frequency (Hz)ï¼Œé¿å… 0 Hz
    """

    df_filtered = df.copy()

    # energy_ratio ä¿è­·ï¼ˆFFT æ°¸é ä¸è¦ç”¨ 1ï¼‰
    energy_ratio = min(max(energy_ratio, 0.0), 0.999)

    nyquist = fs / 2.0

    for col in df.columns:
        data = df[col].to_numpy()

        # ---- 1ï¸âƒ£ NaN / ç„¡æ•ˆè³‡æ–™ä¿è­· ----
        if np.all(np.isnan(data)):
            continue

        valid = ~np.isnan(data)
        if valid.sum() < 10:
            # è³‡æ–™å¤ªçŸ­ï¼Œç›´æ¥ç•¥é
            continue

        x = data[valid]

        # ---- 2ï¸âƒ£ å¸¸æ•¸è¨Šè™Ÿï¼ˆFFT åªå‰© DCï¼‰ ----
        if np.std(x) < 1e-8:
            df_filtered[col] = data
            continue

        # ---- 3ï¸âƒ£ Welch PSD ----
        nperseg = min(1024, len(x))
        f, Pxx = welch(x, fs=fs, nperseg=nperseg)

        cumulative_energy = np.cumsum(Pxx)
        total_energy = cumulative_energy[-1]

        if total_energy <= 0:
            continue

        # ---- 4ï¸âƒ£ æ‰¾ cutoff ----
        cutoff_idx = np.searchsorted(
            cumulative_energy,
            energy_ratio * total_energy
        )
        cutoff_idx = min(cutoff_idx, len(f) - 1)
        cutoff_freq = f[cutoff_idx]

        # ---- 5ï¸âƒ£ cutoff å®‰å…¨ä¿è­· ----
        cutoff_freq = np.clip(
            cutoff_freq,
            min_cutoff,
            0.45 * fs   # ç•™ marginï¼Œé¿å…è²¼ Nyquist
        )

        Wn = cutoff_freq / nyquist
        if not (0 < Wn < 1):
            continue

        # ---- 6ï¸âƒ£ æ¿¾æ³¢ ----
        b, a = butter(order, Wn, btype="low")
        filtered = np.full_like(data, np.nan, dtype=float)
        filtered[valid] = filtfilt(b, a, x)

        df_filtered[col] = filtered

    return df_filtered

# ===========================================(è½‰æ›å™¨)
def data_converter(df): # è½‰æ›è³‡æ–™åªç•™ä¸‹éœ€è¦ç”¨çš„ï¼Œæœªä¾†å¦‚æœraw data æœ‰è®Šæ›´å¯èƒ½éœ€è¦ä¿®æ”¹
    """
    è™•ç†å·¥ä½œ
    1. åªç•™ä¸‹éœ€è¦çš„è³‡æ–™
    2. é€²è¡Œæ­£è² è™Ÿèª¿æ›
    """
    # === 1. Columns used in current fitting stage ===
    # åŸè³‡æ–™ AMBTMP,ET,FX,FY,FZ,IA,MX,MZ,N,NFX,NFY,P,RE,RL,RST,RUN,SA,SL,SR,TSTC,TSTI,TSTO,V
    cols_keep = ['FX', 'FY', 'FZ', 'MX', 'MZ', 'IA', 'P', 'SA', 'SL', 'V']# é…åˆMF62æ¨¡å‹
    df_fit = df[cols_keep].copy()

    # === 2. Sign convention (é›†ä¸­ç®¡ç†è½‰æ›é‚è¼¯) ===
    sign_flip = {
        'FX': -1,
        'FY': -1,
        'FZ': -1,   # load -> positive
        'SA': -1,   # align SA-FY direction
        'SL': -1,
        'MX': -1,
        'MZ': -1,
        'V': 0.28,
        'P' : 1000}  # MZ,MX å…¶å¯¦ä¹Ÿéœ€è¦è½‰æ›ä½†å…ˆä¸ä¿ç•™ ä¹‹å¾ŒåŠ å…¥
        

    for col, s in sign_flip.items():
        df_fit[col] *= s

    return df_fit

# ===========================================(å…¨éƒ¨è™•ç†)
def preprocess_tire_data(
    df: pd.DataFrame,
    mask_builder,                # ğŸ‘ˆ å‚³å…¥ MaskBuilder instance
    mask_type: str = "FX",
    n_head: int = 5,
    n_tail: int = 5,
    fs: float = 1000,
    energy_ratio: float = 0.9,
    order: int = 8
) -> pd.DataFrame:
    """
    å®Œæ•´çš„è¼ªèƒè³‡æ–™æ¸…æ´—æµç¨‹ï¼š
    1. æ¸…æ‰é ­å°¾è³‡æ–™
    2. å»ºç«‹å¸ƒæ—é®ç½©
    3. å¥—ç”¨é®ç½©ä¸¦åˆªæ‰ NaN
    4. ä½é€šæ¿¾æ³¢ï¼ˆå¯é¸ï¼‰
    5. è³‡æ–™è½‰æ›
    """

    # é ­å°¾æ¸…æ´—
    df_cleaned = trim_dataframe_edges(
        df,
        n_head=n_head,
        n_tail=n_tail,
        fill_value=np.nan
    )
    print(f"[Step 1] é ­å°¾æ¸…æ´—å¾Œæœ‰æ•ˆåˆ—æ•¸: {df_cleaned.dropna(how='all').shape[0]} / {len(df_cleaned)}")

    # å»ºç«‹å¸ƒæ—é®ç½©ï¼ˆç”± class è™•ç†ï¼‰
    masks = mask_builder.build_masks(df_cleaned, mask_type=mask_type)
    for k, v in masks.items():
        print(f"[Mask] {k} ç¬¦åˆæ¢ä»¶åˆ—æ•¸: {np.sum(v)} / {len(v)}")

    # å¥—ç”¨ç¸½é®ç½©ï¼ˆMaskBuilder å·²ç¶“å¹«ä½ è¨ˆç®— total_maskï¼‰
    total_mask = masks.pop("total_mask")  # å–å‡ºç¸½é®ç½©ï¼Œå…¶å®ƒå­é®ç½©ä»ä¿ç•™åœ¨å­—å…¸ä¸­
    df_cleaned.loc[~total_mask, :] = np.nan

    # åˆªæ‰æ•´åˆ—éƒ½æ˜¯ NaN çš„è³‡æ–™
    df_cleaned = df_cleaned.dropna(how='all').reset_index(drop=True)
    print(f"[Step 3] å¥—ç”¨ç¸½é®ç½©ä¸¦åˆª NaN å¾Œæœ‰æ•ˆåˆ—æ•¸: {len(df_cleaned)} / {len(df)}")
    
    # ä½é€šæ¿¾æ³¢ï¼ˆåªå°æ•¸å€¼æ¬„ä½ï¼Œå¯é¸ï¼‰
    df_filtered = auto_lowpass_filter(
        df_cleaned,
        fs=fs,
        energy_ratio=energy_ratio,
        order=order
    )
    print(f"[Step 4] æ¿¾æ³¢å¾Œæœ‰æ•ˆåˆ—æ•¸: {df_filtered.dropna(how='all').shape[0]} / {len(df_filtered)}")

    # æœ€å¾Œé€²è¡Œè³‡æ–™è½‰æ›(è½‰æ›å–®ä½ã€åˆªä¸è¦çš„é …ç›®)
    print("[Step 5] é€²è¡Œè³‡æ–™è½‰æ›")
    return data_converter(df_cleaned) # é—œæ‰æ¿¾æ³¢å™¨
    return data_converter(df_filtered)

# ===========================================(åŸ·è¡Œå€åŸŸ)
"""
æª”æ¡ˆè³‡æ–™çµæ§‹
magic_formula/
â”œâ”€ filter/
â”‚  â””â”€ filter.py   â† é€™å€‹æª”æ¡ˆ
â”‚  â””â”€ Filtering_Limits.jsonâ† json
â”œâ”€ data/
â”‚  â””â”€ csv/B2356run23.csvâ† è¦è¼‰å…¥çš„è³‡æ–™
â”‚  â””â”€ csv/B2356run57.csvâ† è¦è¼‰å…¥çš„è³‡æ–™
â”œâ”€ data/
â”‚  â””â”€ Filtered_data/B2356run23_processed.csvâ† å­˜æª”è³‡æ–™
â”‚  â””â”€ Filtered_data/B2356run23_processed.csvâ† å­˜æª”è³‡æ–™
"""
# å»ºç«‹é®ç½©
mask_builder = MaskBuilder(FILTER_DIR / "Filtering_Limits_stage.json")

"""
å°‡å–®ä½è½‰æ›å¾Œçš„ F_data_processed æ‹†æˆç´¯ç©å°æ‡‰ STAGES çš„è³‡æ–™
Stage 1 â†’ IA=0, SL=0
Stage 2 â†’ Stage1 + IA!=0, SL=0
Stage 3~4 â†’ Stage1~2
Stage 5 â†’ Stage3 + SL!=0 (all data)
"""


data_23 = load_tire_data(PROJECT_DIR / "data/csv/B2356run23.csv")
data_57 = load_tire_data(PROJECT_DIR / "data/csv/B2356run57.csv")

print("========è™•ç†23========")
data_23_out = preprocess_tire_data(data_23,mask_builder = mask_builder,mask_type = "23_1")
data_23_out.to_csv(PROJECT_DIR / "data/Filtered_data/B2356run23_processed1.csv", index=False)
data_23_out = preprocess_tire_data(data_23,mask_builder = mask_builder,mask_type = "23_234")
data_23_out.to_csv(PROJECT_DIR / "data/Filtered_data/B2356run23_processed234.csv", index=False)

print("========è™•ç†57========")
data_57_out = preprocess_tire_data(data_57,mask_builder = mask_builder,mask_type = "57_1")
data_57_out.to_csv(PROJECT_DIR / "data/Filtered_data/B2356run57_processed1.csv", index=False)
data_57_out = preprocess_tire_data(data_57,mask_builder = mask_builder,mask_type = "57_234")
data_57_out.to_csv(PROJECT_DIR / "data/Filtered_data/B2356run57_processed234.csv", index=False)
data_57_out = preprocess_tire_data(data_57,mask_builder = mask_builder,mask_type = "57_5")
data_57_out.to_csv(PROJECT_DIR / "data/Filtered_data/B2356run57_processed5.csv", index=False)

print("âœ… è³‡æ–™å·²æˆåŠŸå­˜æˆ CSVï¼")
